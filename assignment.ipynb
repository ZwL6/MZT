{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMC8ommowhQscaWbMlOI4i1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZwL6/MZT/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vgGYzsiFZyE",
        "outputId": "3b1414b7-1dce-4d67-9384-0c3e6bc0e514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=94e9b9cc8c6863019702b1ec88835a7f78c365799920e3e9950db49bb87fd699\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 13 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "nS9UM1hoFizF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cities file\n",
        "!wget https://raw.githubusercontent.com/ZwL6/MZT/main/cities.json\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcIZ1cyMJPs0",
        "outputId": "d6e8980e-b0f4-4480-a869-74188a1a3b5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-29 11:08:12--  https://raw.githubusercontent.com/ZwL6/MZT/main/cities.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15829 (15K) [text/plain]\n",
            "Saving to: ‘cities.json’\n",
            "\n",
            "cities.json         100%[===================>]  15.46K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-06-29 11:08:12 (2.39 MB/s) - ‘cities.json’ saved [15829/15829]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making standerd route\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Set seed\n",
        "random.seed(1)\n",
        "with open('cities.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "cities = [d['city'] for d in data]\n",
        "\n",
        "merchandise = ['apple', 'tomatoes', 'butter', 'water', 'milk', 'pens', 'honey']\n",
        "\n",
        "routes = []\n",
        "\n",
        "for i in range(1000):\n",
        "    route = {}\n",
        "    route['id'] = i\n",
        "\n",
        "    # Generate a list of non-repeating random cities\n",
        "    city_sample = random.sample(cities, 3)\n",
        "\n",
        "    # Randomly generate the number of merchandise\n",
        "    num_merchandise = random.randint(1, 10)\n",
        "\n",
        "    # Randomly select merchandise types\n",
        "    merchandise_sample = random.sample(merchandise, random.randint(3, 5))\n",
        "\n",
        "    # Build the route dictionary format\n",
        "    route['route'] = []\n",
        "    for j in range(2):\n",
        "        route_info = {}\n",
        "        route_info['from'] = city_sample[j]\n",
        "        route_info['to'] = city_sample[j+1]\n",
        "\n",
        "        # Generate random merchandise quantities for each route\n",
        "        merchandise_dict = {}\n",
        "        for m in merchandise_sample:\n",
        "            merchandise_dict[m] = random.randint(1, num_merchandise)\n",
        "\n",
        "        route_info['merchandise'] = merchandise_dict\n",
        "\n",
        "        route['route'].append(route_info)\n",
        "\n",
        "    routes.append(route)\n",
        "\n",
        "# Write the route list to a JSON file without corrupt records\n",
        "valid_routes = [r for r in routes if 'route' in r and len(r['route']) == 2]\n",
        "with open('routes.json', 'w') as file:\n",
        "    json.dump(routes, file, indent=4)\n"
      ],
      "metadata": {
        "id": "qj8cYyhKSHBl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download routes\n",
        "# from google.colab import files\n",
        "# files.download('routes.json')\n"
      ],
      "metadata": {
        "id": "uNZs3ShmVCAl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making actual route\n",
        "\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "\n",
        "# Set seed\n",
        "random.seed(2)\n",
        "\n",
        "# Read the JSON file\n",
        "with open('cities.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract city names\n",
        "cities = [item['city'] for item in data]\n",
        "\n",
        "# Define merchandise types\n",
        "merchandise_types = ['apple', 'tomatoes', 'butter', 'water', 'milk', 'pens', 'honey']\n",
        "\n",
        "with open('routes.json', 'r') as file:\n",
        "    routes = json.load(file)\n",
        "\n",
        "act_routes = []\n",
        "\n",
        "for route in routes:\n",
        "    if len(route['route']) < 2:\n",
        "        continue  # Skip routes with less than two cities\n",
        "\n",
        "    for _ in range(10):\n",
        "        act_route = copy.deepcopy(route)  # Use deepcopy to avoid modifying the original route\n",
        "\n",
        "        # Randomly select a city to modify\n",
        "        modified_city_index = random.randint(0, len(act_route['route']) - 1)\n",
        "        modified_city = act_route['route'][modified_city_index]\n",
        "\n",
        "        # Randomly decide whether to modify city\n",
        "        if random.choice([True, False]):\n",
        "            # Modify the selected city\n",
        "            new_city = random.choice(cities)\n",
        "            modified_city['from'] = new_city\n",
        "\n",
        "            # If the modified city is the second city, modify it throughout the route\n",
        "            if modified_city_index == 1:\n",
        "                # Replace the modified city with a new city\n",
        "                act_route['route'][modified_city_index]['from'] = new_city\n",
        "                # Connect the cities before and after the replaced city\n",
        "                act_route['route'][modified_city_index - 1]['to'] = new_city\n",
        "                if modified_city_index + 1 < len(act_route['route']):\n",
        "                    act_route['route'][modified_city_index]['to'] = act_route['route'][modified_city_index + 1]['from']\n",
        "\n",
        "        # Randomly modify merchandise\n",
        "        for city_route in act_route['route']:\n",
        "            # Select random merchandise types\n",
        "            selected_merchandise = random.sample(merchandise_types, random.randint(1, len(merchandise_types)))\n",
        "            # Assign random quantities to selected merchandise\n",
        "            city_route['merchandise'] = {item: random.randint(1, 5) for item in selected_merchandise}\n",
        "\n",
        "        act_routes.append(act_route)\n",
        "\n",
        "# Write the act routes list to a new JSON file\n",
        "with open('act_routes.json', 'w') as file:\n",
        "    json.dump(act_routes, file, indent=4)"
      ],
      "metadata": {
        "id": "CGJurVstWvbv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the actual routes\n",
        "# from google.colab import files\n",
        "# files.download('act_routes.json')"
      ],
      "metadata": {
        "id": "WOqkwzTkX1L5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from Levenshtein import distance\n",
        "\n",
        "# Function for calculating route edit distance similarity\n",
        "def calculate_similarity(route1, route2):\n",
        "    lev_distance = distance(route1, route2)\n",
        "    max_length = max(len(route1), len(route2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# Function for calculating marchandise edit distance similarity\n",
        "def calculate_merchandise_similarity(merch1, merch2):\n",
        "    lev_distance = distance(merch1, merch2)\n",
        "    max_length = max(len(merch1), len(merch2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# open standard route file\n",
        "with open('routes.json', 'r') as file:\n",
        "    routes = json.load(file)\n",
        "\n",
        "# open actual route file\n",
        "with open('act_routes.json', 'r') as file:\n",
        "    act_routes = json.load(file)\n",
        "\n",
        "# Create a dictionary to store the most similar route for each actual route\n",
        "most_similar_routes = defaultdict(list)\n",
        "\n",
        "# Correct prediction counter\n",
        "correct_predictions = 0\n",
        "\n",
        "# Iterate through all actual routes\n",
        "for act_route in act_routes:\n",
        "    act_route_id = act_route['id']\n",
        "    act_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in act_route['route']])\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "    # route similarity calculating\n",
        "    for standard_route in routes:\n",
        "        standard_route_id = standard_route['id']\n",
        "        standard_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in standard_route['route']])\n",
        "\n",
        "        route_similarity = calculate_similarity(standard_route_str, act_route_str)\n",
        "\n",
        "        # merchandise similarity calculating\n",
        "        merchandise_similarity = 0\n",
        "        for i, route in enumerate(act_route['route']):\n",
        "            act_merchandise = route['merchandise']\n",
        "            standard_merchandise = standard_route['route'][0]['merchandise']\n",
        "            merchandise_similarity += calculate_merchandise_similarity(str(standard_merchandise), str(act_merchandise))\n",
        "        merchandise_similarity /= len(standard_route['route'])\n",
        "\n",
        "        #total similarity calculating\n",
        "        total_similarity = (route_similarity + merchandise_similarity) / 2\n",
        "        similarities.append((standard_route_id, total_similarity))\n",
        "\n",
        "    # sort the max similarity\n",
        "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Find the most similar route\n",
        "    max_similarity = similarities[0]\n",
        "\n",
        "    # Store the most similar route for this actual route\n",
        "    most_similar_routes[act_route_id].append(max_similarity)\n",
        "\n",
        "    # If the actual route id is the same as the predicted route id, increment the correct prediction counter\n",
        "    if act_route_id == max_similarity[0]:\n",
        "        correct_predictions += 1\n",
        "\n",
        "# Print the most similar routes for all actual routes\n",
        "# for act_route_id, max_similarities in most_similar_routes.items():\n",
        "#    for i, max_similarity in enumerate(max_similarities):\n",
        "#        print(f\"Max similarity for actual route {act_route_id}-{i+1}: Standard Route {max_similarity[0]} with similarity {max_similarity[1]}\")\n",
        "\n",
        "# Calculate and print the prediction accuracy\n",
        "accuracy = correct_predictions / len(act_routes)\n",
        "print(f\"Prediction accuracy: {accuracy * 100}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdfcXzp1kVSA",
        "outputId": "6f34b87b-f7d6-4a78-cc91-91ac03cd0aaf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 python-Levenshtein-0.21.1 rapidfuzz-3.1.1\n",
            "Prediction accuracy: 82.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'standard routes' file to Spark DataFrame\n",
        "import pandas as pd\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load data from JSON file\n",
        "with open('routes.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize an empty DataFrame to store the processed data\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate over each element\n",
        "for element in data:\n",
        "  id = element['id']\n",
        "\n",
        "# Iterate over routes\n",
        "  for route in element['route']:\n",
        "    from_city = route['from']\n",
        "    to_city = route['to']\n",
        "\n",
        "    # Iterate over merchandise\n",
        "    for merchandise, quantity in route['merchandise'].items():\n",
        "        # Append data to DataFrame\n",
        "        df = df.append({\n",
        "            'id': id,\n",
        "            'from': from_city,\n",
        "            'to': to_city,\n",
        "            'merchandise': merchandise,\n",
        "            'quantity': quantity\n",
        "        }, ignore_index=True)\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Convert DataFrame to Spark DataFrame\n",
        "st_routes_df = spark.createDataFrame(df)"
      ],
      "metadata": {
        "id": "uoS_LRqHXCNl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Create a new column that is the merchandise column value repeated quantity times\n",
        "str_df = st_routes_df.withColumn('merchandise_quantity', expr(\"repeat(merchandise, quantity)\"))\n",
        "str_df = str_df.drop('merchandise','quantity')\n",
        "\n",
        "str_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da0fAyHq0Q4J",
        "outputId": "440ed992-9842-4295-f5c2-6bebc0239e2e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+-----------+--------------------+\n",
            "| id|       from|         to|merchandise_quantity|\n",
            "+---+-----------+-----------+--------------------+\n",
            "|  0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|  0|    Helmond|Schoonhoven|          honeyhoney|\n",
            "|  0|    Helmond|Schoonhoven|                pens|\n",
            "|  0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0|Schoonhoven|    Zaandam|               honey|\n",
            "+---+-----------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the duplicated routes\n",
        "stpaths = str_df.dropDuplicates([\"id\", \"from\", \"to\"])\n",
        "\n",
        "stpaths.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHfkTc_kHA5_",
        "outputId": "f82e84e4-5448-47ff-ea29-5369aabcd0ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+------------+--------------------+\n",
            "| id|        from|          to|merchandise_quantity|\n",
            "+---+------------+------------+--------------------+\n",
            "|  0|     Helmond| Schoonhoven|waterwaterwaterwater|\n",
            "|  0| Schoonhoven|     Zaandam|waterwaterwaterwater|\n",
            "|  1|Klazienaveen|   The Hague|                pens|\n",
            "|  1|      Nuenen|Klazienaveen|penspenspenspensp...|\n",
            "|  2|    Enschede|   Harlingen|    milkmilkmilkmilk|\n",
            "+---+------------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "# Load data from JSON file\n",
        "with open('act_routes.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize an empty DataFrame to store the processed data\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Dictionary to store the counter for each unique ID\n",
        "id_counter = {}\n",
        "\n",
        "# Iterate over each element\n",
        "for element in data:\n",
        "    id = element['id']\n",
        "\n",
        "    # Increment the counter for each unique ID\n",
        "    if id in id_counter:\n",
        "        id_counter[id] += 1\n",
        "    else:\n",
        "        id_counter[id] = 1\n",
        "\n",
        "    # Counter for each ID\n",
        "    counter = id_counter[id]\n",
        "\n",
        "    # Iterate over routes\n",
        "    for route in element['route']:\n",
        "        from_city = route['from']\n",
        "        to_city = route['to']\n",
        "\n",
        "        # Iterate over merchandise\n",
        "        for merchandise, quantity in route['merchandise'].items():\n",
        "            # Append data to DataFrame with modified ID\n",
        "            df = df.append({\n",
        "                'id': f\"{id}-{counter}\",  # Assign modified ID with counter\n",
        "                'original_id': id,  # Store original ID\n",
        "                'from': from_city,\n",
        "                'to': to_city,\n",
        "                'merchandise': merchandise,\n",
        "                'quantity': quantity\n",
        "            }, ignore_index=True)\n",
        "\n",
        "# Convert DataFrame to Spark DataFrame\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "ac_routes_df = spark.createDataFrame(df)\n",
        "\n",
        "# Assign sequential counts to duplicate IDs\n",
        "ac_routes_df = ac_routes_df.withColumn('new_id', monotonically_increasing_id())\n"
      ],
      "metadata": {
        "id": "EpXKTrpdhTib"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine merchandies and quantity\n",
        "acr_df = ac_routes_df.withColumn('merchandise_quantity', expr(\"repeat(merchandise, quantity)\"))\n",
        "acr_df = acr_df.drop('merchandise', 'quantity', 'new_id')\n",
        "\n",
        "acr_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jcEdj7rKeBB",
        "outputId": "f02cda47-9f67-45ea-df27-e1ad5709291a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+-----------+-----------+--------------------+\n",
            "| id|original_id|       from|         to|merchandise_quantity|\n",
            "+---+-----------+-----------+-----------+--------------------+\n",
            "|0-1|          0|Barendrecht|Schoonhoven|     honeyhoneyhoney|\n",
            "|0-1|          0|Barendrecht|Schoonhoven|tomatoestomatoest...|\n",
            "|0-1|          0|Barendrecht|Schoonhoven|        butterbutter|\n",
            "|0-1|          0|Schoonhoven|    Zaandam|appleappleappleapple|\n",
            "|0-1|          0|Schoonhoven|    Zaandam|milkmilkmilkmilkmilk|\n",
            "+---+-----------+-----------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the duplicated routes\n",
        "acpaths = acr_df.dropDuplicates([\"id\", \"original_id\", \"from\", \"to\"])\n",
        "\n",
        "acpaths.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ZxDm_V8GkW",
        "outputId": "8b3c0b67-c092-479d-84d9-c3d629e6dc7e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+-----------+-----------+--------------------+\n",
            "|  id|original_id|       from|         to|merchandise_quantity|\n",
            "+----+-----------+-----------+-----------+--------------------+\n",
            "| 0-1|          0|Barendrecht|Schoonhoven|     honeyhoneyhoney|\n",
            "| 0-1|          0|Schoonhoven|    Zaandam|appleappleappleapple|\n",
            "|0-10|          0| Den Helder|Schoonhoven|          waterwater|\n",
            "|0-10|          0|Schoonhoven|    Zaandam|    penspenspenspens|\n",
            "| 0-2|          0|   Enschede|    Zaandam|tomatoestomatoest...|\n",
            "+----+-----------+-----------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns\n",
        "pa_standard = stpaths.selectExpr(\"id as st_id\", \"from as st_from\", \"to as st_to\")\n",
        "pa_actual = acpaths.selectExpr(\"id as act_id\", \"original_id\", \"from as act_from\", \"to as act_to\")\n",
        "\n",
        "pa_actual.show()\n",
        "\n",
        "df_joined = pa_actual.join(pa_standard, (pa_actual.original_id == pa_standard.st_id), 'outer')\n",
        "\n",
        "df_joined.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVmfmim1Fipk",
        "outputId": "40a1367a-0f6e-4737-e840-89ef1eaeaf88"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+---------------+----------------+\n",
            "|act_id|original_id|       act_from|          act_to|\n",
            "+------+-----------+---------------+----------------+\n",
            "|   1-8|          1|   Klazienaveen|       The Hague|\n",
            "|  12-6|         12|       Franeker|        Schinnen|\n",
            "|  13-3|         13|         Raalte|Koog aan de Zaan|\n",
            "|  21-8|         21|         Vianen|       Nijverdal|\n",
            "|  35-5|         35|      Apeldoorn|       Breukelen|\n",
            "| 40-10|         40|       Hillegom|     Heerlerbaan|\n",
            "|  54-2|         54|       Blaricum|        Kerkrade|\n",
            "| 55-10|         55|    Barendrecht|        Uithoorn|\n",
            "|  66-9|         66|       Rosmalen|         Eerbeek|\n",
            "|  68-3|         68|       Zeewolde|        Ubbergen|\n",
            "|  74-9|         74|    Heerlerbaan|        Blaricum|\n",
            "|  87-7|         87|         Raalte|          Raalte|\n",
            "|  89-9|         89|        Naarden|          Borger|\n",
            "|  94-8|         94|        Helmond|           Wezep|\n",
            "|  98-3|         98|     Amersfoort|          Bunnik|\n",
            "| 102-6|        102|  ?-Gravenzande|         Wijchen|\n",
            "|106-10|        106|      Beverwijk|       Rotterdam|\n",
            "| 107-8|        107|         Putten|       Montfoort|\n",
            "| 120-3|        120|         Voorst|           Hulst|\n",
            "| 129-4|        129|?-Hertogenbosch|        Drachten|\n",
            "+------+-----------+---------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+-----------+-----------+-----------+-----+-----------+-----------+\n",
            "|act_id|original_id|   act_from|     act_to|st_id|    st_from|      st_to|\n",
            "+------+-----------+-----------+-----------+-----+-----------+-----------+\n",
            "|   0-5|          0|    Helmond|Schoonhoven|    0|    Helmond|Schoonhoven|\n",
            "|   0-5|          0|    Helmond|Schoonhoven|    0|Schoonhoven|    Zaandam|\n",
            "|   0-1|          0|Schoonhoven|    Zaandam|    0|    Helmond|Schoonhoven|\n",
            "|   0-1|          0|Schoonhoven|    Zaandam|    0|Schoonhoven|    Zaandam|\n",
            "|   0-4|          0|    Helmond|Schoonhoven|    0|    Helmond|Schoonhoven|\n",
            "+------+-----------+-----------+-----------+-----+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from Levenshtein import distance\n",
        "\n",
        "def levenshtein_distance(s1, s2):\n",
        "    return distance(s1, s2)\n",
        "\n",
        "levenshtein_distance_udf = udf(levenshtein_distance, IntegerType())\n"
      ],
      "metadata": {
        "id": "B4TmnMW2BtIH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}