{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbtC0ZYEKeVzry9RBvBNzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZwL6/MZT/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vgGYzsiFZyE",
        "outputId": "c6bf577d-9fd9-4e0f-9a9a-136e963f9068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "openjdk-8-jdk-headless is already the newest version (8u372-ga~us1-0ubuntu1~20.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "nS9UM1hoFizF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cities file\n",
        "!wget https://raw.githubusercontent.com/ZwL6/MZT/main/cities.json\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcIZ1cyMJPs0",
        "outputId": "e6ce027e-a288-496c-e66e-1c0bdd1a4563"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-28 18:13:27--  https://raw.githubusercontent.com/ZwL6/MZT/main/cities.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15829 (15K) [text/plain]\n",
            "Saving to: ‘cities.json.1’\n",
            "\n",
            "cities.json.1       100%[===================>]  15.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-28 18:13:27 (56.7 MB/s) - ‘cities.json.1’ saved [15829/15829]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making standerd route\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Set seed\n",
        "random.seed(1)\n",
        "with open('cities.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "cities = [d['city'] for d in data]\n",
        "\n",
        "merchandise = ['apple', 'tomatoes', 'butter', 'water', 'milk', 'pens', 'honey']\n",
        "\n",
        "routes = []\n",
        "\n",
        "for i in range(1000):\n",
        "    route = {}\n",
        "    route['id'] = i\n",
        "\n",
        "    # Generate a list of non-repeating random cities\n",
        "    city_sample = random.sample(cities, 3)\n",
        "\n",
        "    # Randomly generate the number of merchandise\n",
        "    num_merchandise = random.randint(1, 10)\n",
        "\n",
        "    # Randomly select merchandise types\n",
        "    merchandise_sample = random.sample(merchandise, random.randint(3, 5))\n",
        "\n",
        "    # Build the route dictionary format\n",
        "    route['route'] = []\n",
        "    for j in range(2):\n",
        "        route_info = {}\n",
        "        route_info['from'] = city_sample[j]\n",
        "        route_info['to'] = city_sample[j+1]\n",
        "\n",
        "        # Generate random merchandise quantities for each route\n",
        "        merchandise_dict = {}\n",
        "        for m in merchandise_sample:\n",
        "            merchandise_dict[m] = random.randint(1, num_merchandise)\n",
        "\n",
        "        route_info['merchandise'] = merchandise_dict\n",
        "\n",
        "        route['route'].append(route_info)\n",
        "\n",
        "    routes.append(route)\n",
        "\n",
        "# Write the route list to a JSON file without corrupt records\n",
        "valid_routes = [r for r in routes if 'route' in r and len(r['route']) == 2]\n",
        "with open('routes.json', 'w') as file:\n",
        "    json.dump(routes, file, indent=4)\n"
      ],
      "metadata": {
        "id": "qj8cYyhKSHBl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download routes\n",
        "# from google.colab import files\n",
        "# files.download('routes.json')\n"
      ],
      "metadata": {
        "id": "uNZs3ShmVCAl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making actual route\n",
        "\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "\n",
        "# Set seed\n",
        "random.seed(2)\n",
        "\n",
        "# Read the JSON file\n",
        "with open('cities.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract city names\n",
        "cities = [item['city'] for item in data]\n",
        "\n",
        "# Define merchandise types\n",
        "merchandise_types = ['apple', 'tomatoes', 'butter', 'water', 'milk', 'pens', 'honey']\n",
        "\n",
        "with open('routes.json', 'r') as file:\n",
        "    routes = json.load(file)\n",
        "\n",
        "act_routes = []\n",
        "\n",
        "for route in routes:\n",
        "    if len(route['route']) < 2:\n",
        "        continue  # Skip routes with less than two cities\n",
        "\n",
        "    for _ in range(10):\n",
        "        act_route = copy.deepcopy(route)  # Use deepcopy to avoid modifying the original route\n",
        "\n",
        "        # Randomly select a city to modify\n",
        "        modified_city_index = random.randint(0, len(act_route['route']) - 1)\n",
        "        modified_city = act_route['route'][modified_city_index]\n",
        "\n",
        "        # Randomly decide whether to modify city\n",
        "        if random.choice([True, False]):\n",
        "            # Modify the selected city\n",
        "            new_city = random.choice(cities)\n",
        "            modified_city['from'] = new_city\n",
        "\n",
        "            # If the modified city is the second city, modify it throughout the route\n",
        "            if modified_city_index == 1:\n",
        "                # Replace the modified city with a new city\n",
        "                act_route['route'][modified_city_index]['from'] = new_city\n",
        "                # Connect the cities before and after the replaced city\n",
        "                act_route['route'][modified_city_index - 1]['to'] = new_city\n",
        "                if modified_city_index + 1 < len(act_route['route']):\n",
        "                    act_route['route'][modified_city_index]['to'] = act_route['route'][modified_city_index + 1]['from']\n",
        "\n",
        "        # Randomly modify merchandise\n",
        "        for city_route in act_route['route']:\n",
        "            # Select random merchandise types\n",
        "            selected_merchandise = random.sample(merchandise_types, random.randint(1, len(merchandise_types)))\n",
        "            # Assign random quantities to selected merchandise\n",
        "            city_route['merchandise'] = {item: random.randint(1, 5) for item in selected_merchandise}\n",
        "\n",
        "        act_routes.append(act_route)\n",
        "\n",
        "# Write the act routes list to a new JSON file\n",
        "with open('act_routes.json', 'w') as file:\n",
        "    json.dump(act_routes, file, indent=4)"
      ],
      "metadata": {
        "id": "CGJurVstWvbv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the actual routes\n",
        "# from google.colab import files\n",
        "# files.download('act_routes.json')"
      ],
      "metadata": {
        "id": "WOqkwzTkX1L5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from Levenshtein import distance\n",
        "\n",
        "# Function for calculating route edit distance similarity\n",
        "def calculate_similarity(route1, route2):\n",
        "    lev_distance = distance(route1, route2)\n",
        "    max_length = max(len(route1), len(route2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# Function for calculating marchandise edit distance similarity\n",
        "def calculate_merchandise_similarity(merch1, merch2):\n",
        "    lev_distance = distance(merch1, merch2)\n",
        "    max_length = max(len(merch1), len(merch2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# open standard route file\n",
        "with open('routes.json', 'r') as file:\n",
        "    routes = json.load(file)\n",
        "\n",
        "# open actual route file\n",
        "with open('act_routes.json', 'r') as file:\n",
        "    act_routes = json.load(file)\n",
        "\n",
        "# Create a dictionary to store the most similar route for each actual route\n",
        "most_similar_routes = defaultdict(list)\n",
        "\n",
        "# Correct prediction counter\n",
        "correct_predictions = 0\n",
        "\n",
        "# Iterate through all actual routes\n",
        "for act_route in act_routes:\n",
        "    act_route_id = act_route['id']\n",
        "    act_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in act_route['route']])\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "    # route similarity calculating\n",
        "    for standard_route in routes:\n",
        "        standard_route_id = standard_route['id']\n",
        "        standard_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in standard_route['route']])\n",
        "\n",
        "        route_similarity = calculate_similarity(standard_route_str, act_route_str)\n",
        "\n",
        "        # merchandise similarity calculating\n",
        "        merchandise_similarity = 0\n",
        "        for i, route in enumerate(act_route['route']):\n",
        "            act_merchandise = route['merchandise']\n",
        "            standard_merchandise = standard_route['route'][0]['merchandise']\n",
        "            merchandise_similarity += calculate_merchandise_similarity(str(standard_merchandise), str(act_merchandise))\n",
        "        merchandise_similarity /= len(standard_route['route'])\n",
        "\n",
        "        #total similarity calculating\n",
        "        total_similarity = (route_similarity + merchandise_similarity) / 2\n",
        "        similarities.append((standard_route_id, total_similarity))\n",
        "\n",
        "    # sort the max similarity\n",
        "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Find the most similar route\n",
        "    max_similarity = similarities[0]\n",
        "\n",
        "    # Store the most similar route for this actual route\n",
        "    most_similar_routes[act_route_id].append(max_similarity)\n",
        "\n",
        "    # If the actual route id is the same as the predicted route id, increment the correct prediction counter\n",
        "    if act_route_id == max_similarity[0]:\n",
        "        correct_predictions += 1\n",
        "\n",
        "# Print the most similar routes for all actual routes\n",
        "# for act_route_id, max_similarities in most_similar_routes.items():\n",
        "#    for i, max_similarity in enumerate(max_similarities):\n",
        "#        print(f\"Max similarity for actual route {act_route_id}-{i+1}: Standard Route {max_similarity[0]} with similarity {max_similarity[1]}\")\n",
        "\n",
        "# Calculate and print the prediction accuracy\n",
        "accuracy = correct_predictions / len(act_routes)\n",
        "print(f\"Prediction accuracy: {accuracy * 100}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdfcXzp1kVSA",
        "outputId": "0384911b-41d2-4bd8-8699-9089d8420e52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Prediction accuracy: 82.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "# Create Spark Session\n",
        "spark = SparkSession.builder.appName('RouteSimilarity').getOrCreate()\n",
        "\n",
        "# Load data\n",
        "routes_df = spark.read.json('routes.json')\n",
        "act_routes_df = spark.read.json('act_routes.json')\n"
      ],
      "metadata": {
        "id": "5jcEdj7rKeBB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "routes_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "QWIseYj0Q0LR",
        "outputId": "48ae76d9-3974-40f8-afeb-b035540db530"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-082a9af15db3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroutes_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Since Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count()."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Edit distance calculation\n",
        "# Create a new SparkContext\n",
        "sc.stop()\n",
        "sc = SparkContext(\"local\", \"RouteSimilarity\")\n",
        "\n",
        "# Load routes data\n",
        "routes_rdd = sc.wholeTextFiles(\"routes.json\").flatMap(lambda x: json.loads(x[1]))\n",
        "act_routes_rdd = sc.wholeTextFiles(\"act_routes.json\").flatMap(lambda x: json.loads(x[1]))\n",
        "\n",
        "# Parse JSON and extract relevant data\n",
        "routes = routes_rdd.map(lambda x: x)\n",
        "act_routes = act_routes_rdd.map(lambda x: x)\n",
        "\n",
        "\n",
        "# Extract standard route\n",
        "standard_route = routes.filter(lambda x: x['id'] == 0).map(lambda x: x['route'][0])\n",
        "standard_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in standard_route.collect()])\n",
        "\n",
        "\n",
        "# Compute similarity for each act_route\n",
        "similarities = act_routes.flatMap(lambda x: x['route']).map(lambda x: (x['id'], x['route'])).map(lambda x: (x[0], ' '.join([f\"{route['from']} {route['to']}\" for route in x[1]]))) \\\n",
        "    .map(lambda x: (x[0], calculate_similarity(standard_route_str, x[1]))) \\\n",
        "    .reduceByKey(lambda x, y: (x*0.8 + y*0.2) / 2)\n",
        "\n",
        "# Compute similarity for route 1 only\n",
        "similarity_1 = similarities.filter(lambda x: x[0] == 1)\n",
        "\n",
        "# Collect the result and print it\n",
        "for x in similarity_1.collect():\n",
        "    print(f\"Similarity for route {x[0]}: {x[1]}\")\n",
        "\n",
        "# Stop the SparkContext\n",
        "sc.stop()\n",
        "\n"
      ],
      "metadata": {
        "id": "lADtR0vCYa45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}