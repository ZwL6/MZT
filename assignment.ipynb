{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ3W1NQxHo1xdNxpiXJbwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZwL6/MZT/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vgGYzsiFZyE",
        "outputId": "26de0083-1010-46d3-baa2-202ef5d09b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=809f947f206a4c4925eda3e5d77f8c632d68f07caef1ce7d6e024ea2870c9d9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "nS9UM1hoFizF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cities file\n",
        "!wget https://raw.githubusercontent.com/ZwL6/MZT/main/cities.json\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcIZ1cyMJPs0",
        "outputId": "0f81bec8-e197-4550-996c-b489121d0e3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-29 19:09:22--  https://raw.githubusercontent.com/ZwL6/MZT/main/cities.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15829 (15K) [text/plain]\n",
            "Saving to: ‘cities.json’\n",
            "\n",
            "\rcities.json           0%[                    ]       0  --.-KB/s               \rcities.json         100%[===================>]  15.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-29 19:09:22 (67.9 MB/s) - ‘cities.json’ saved [15829/15829]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making standerd route\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Set seed\n",
        "random.seed(1)\n",
        "with open('cities.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "cities = [d['city'] for d in data]\n",
        "\n",
        "merchandise = ['apple', 'tomatoes', 'butter', 'water', 'milk', 'pens', 'honey']\n",
        "\n",
        "routes = []\n",
        "\n",
        "for i in range(1000):\n",
        "    route = {}\n",
        "    route['id'] = i\n",
        "\n",
        "    # Generate a list of non-repeating random cities\n",
        "    city_sample = random.sample(cities, 3)\n",
        "\n",
        "    # Randomly generate the number of merchandise\n",
        "    num_merchandise = random.randint(1, 10)\n",
        "\n",
        "    # Randomly select merchandise types\n",
        "    merchandise_sample = random.sample(merchandise, random.randint(3, 5))\n",
        "\n",
        "    # Build the route dictionary format\n",
        "    route['route'] = []\n",
        "    for j in range(2):\n",
        "        route_info = {}\n",
        "        route_info['from'] = city_sample[j]\n",
        "        route_info['to'] = city_sample[j+1]\n",
        "\n",
        "        # Generate random merchandise quantities for each route\n",
        "        merchandise_dict = {}\n",
        "        for m in merchandise_sample:\n",
        "            merchandise_dict[m] = random.randint(1, num_merchandise)\n",
        "\n",
        "        route_info['merchandise'] = merchandise_dict\n",
        "\n",
        "        route['route'].append(route_info)\n",
        "\n",
        "    routes.append(route)\n",
        "\n",
        "# Write the route list to a JSON file without corrupt records\n",
        "valid_routes = [r for r in routes if 'route' in r and len(r['route']) == 2]\n",
        "with open('routes.json', 'w') as file:\n",
        "    json.dump(routes, file, indent=4)\n"
      ],
      "metadata": {
        "id": "qj8cYyhKSHBl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download routes\n",
        "# from google.colab import files\n",
        "# files.download('routes.json')\n"
      ],
      "metadata": {
        "id": "uNZs3ShmVCAl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a4ed61e6-1c4d-42b0-9d75-ddf83957a351"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40f1296f-d610-48c6-ba80-57dfacfd6f38\", \"routes.json\", 618314)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making actual route\n",
        "\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "\n",
        "# Set seed\n",
        "random.seed(2)\n",
        "\n",
        "# Read the JSON file\n",
        "with open('cities.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract city names\n",
        "cities = [item['city'] for item in data]\n",
        "\n",
        "# Define merchandise types\n",
        "merchandise_types = ['apple', 'tomatoes', 'butter', 'water', 'milk', 'pens', 'honey']\n",
        "\n",
        "with open('routes.json', 'r') as file:\n",
        "    routes = json.load(file)\n",
        "\n",
        "act_routes = []\n",
        "\n",
        "for route in routes:\n",
        "    if len(route['route']) < 2:\n",
        "        continue  # Skip routes with less than two cities\n",
        "\n",
        "    for _ in range(10):\n",
        "        act_route = copy.deepcopy(route)  # Use deepcopy to avoid modifying the original route\n",
        "\n",
        "        # Randomly select a city to modify\n",
        "        modified_city_index = random.randint(0, len(act_route['route']) - 1)\n",
        "        modified_city = act_route['route'][modified_city_index]\n",
        "\n",
        "        # Randomly decide whether to modify city\n",
        "        if random.choice([True, False]):\n",
        "            # Modify the selected city\n",
        "            new_city = random.choice(cities)\n",
        "            modified_city['from'] = new_city\n",
        "\n",
        "            # If the modified city is the second city, modify it throughout the route\n",
        "            if modified_city_index == 1:\n",
        "                # Replace the modified city with a new city\n",
        "                act_route['route'][modified_city_index]['from'] = new_city\n",
        "                # Connect the cities before and after the replaced city\n",
        "                act_route['route'][modified_city_index - 1]['to'] = new_city\n",
        "                if modified_city_index + 1 < len(act_route['route']):\n",
        "                    act_route['route'][modified_city_index]['to'] = act_route['route'][modified_city_index + 1]['from']\n",
        "\n",
        "        # Randomly modify merchandise\n",
        "        for city_route in act_route['route']:\n",
        "          # Randomly decide whether to modify merchandise\n",
        "          if random.choice([True, False]):\n",
        "            # Select a random merchandise type\n",
        "            modified_merchandise = random.choice(list(city_route['merchandise'].keys()))\n",
        "            # Modify the quantity or replace the merchandise type\n",
        "            if random.choice([True, False]):\n",
        "              # Modify the quantity\n",
        "              city_route['merchandise'][modified_merchandise] = random.randint(1, 5)\n",
        "            else:\n",
        "              # Replace the merchandise type\n",
        "              new_merchandise = random.choice(merchandise_types)\n",
        "              if modified_merchandise in city_route['merchandise']:\n",
        "                city_route['merchandise'][new_merchandise] = city_route['merchandise'][modified_merchandise]\n",
        "                del city_route['merchandise'][modified_merchandise]\n",
        "\n",
        "\n",
        "        # Randomly modify merchandise\n",
        "        #for city_route in act_route['route']:\n",
        "            # Select random merchandise types\n",
        "            #selected_merchandise = random.sample(merchandise_types, random.randint(1, len(merchandise_types)))\n",
        "            # Assign random quantities to selected merchandise\n",
        "            #city_route['merchandise'] = {item: random.randint(1, 5) for item in selected_merchandise}\n",
        "\n",
        "        act_routes.append(act_route)\n",
        "\n",
        "# Write the act routes list to a new JSON file\n",
        "with open('act_routes.json', 'w') as file:\n",
        "    json.dump(act_routes, file, indent=4)"
      ],
      "metadata": {
        "id": "CGJurVstWvbv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the actual routes\n",
        "# from google.colab import files\n",
        "# files.download('act_routes.json')"
      ],
      "metadata": {
        "id": "WOqkwzTkX1L5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5cc85623-e788-44dd-8dc8-51ef81f0fc26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_01128b2d-3051-4582-8b2b-810492821f8d\", \"act_routes.json\", 6090500)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from Levenshtein import distance\n",
        "\n",
        "# Function for calculating route edit distance similarity\n",
        "def calculate_similarity(route1, route2):\n",
        "    lev_distance = distance(route1, route2)\n",
        "    max_length = max(len(route1), len(route2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# Function for calculating marchandise edit distance similarity\n",
        "def calculate_merchandise_similarity(merch1, merch2):\n",
        "    lev_distance = distance(merch1, merch2)\n",
        "    max_length = max(len(merch1), len(merch2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# open standard route file\n",
        "with open('routes.json', 'r') as file:\n",
        "    routes = json.load(file)\n",
        "\n",
        "# open actual route file\n",
        "with open('act_routes.json', 'r') as file:\n",
        "    act_routes = json.load(file)\n",
        "\n",
        "# Create a dictionary to store the most similar route for each actual route\n",
        "most_similar_routes = defaultdict(list)\n",
        "\n",
        "# Correct prediction counter\n",
        "correct_predictions = 0\n",
        "\n",
        "# Iterate through all actual routes\n",
        "for act_route in act_routes:\n",
        "    act_route_id = act_route['id']\n",
        "    act_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in act_route['route']])\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "    # route similarity calculating\n",
        "    for standard_route in routes:\n",
        "        standard_route_id = standard_route['id']\n",
        "        standard_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in standard_route['route']])\n",
        "\n",
        "        route_similarity = calculate_similarity(standard_route_str, act_route_str)\n",
        "\n",
        "        # merchandise similarity calculating\n",
        "        merchandise_similarity = 0\n",
        "        for i, route in enumerate(act_route['route']):\n",
        "            act_merchandise = route['merchandise']\n",
        "            standard_merchandise = standard_route['route'][0]['merchandise']\n",
        "            merchandise_similarity += calculate_merchandise_similarity(str(standard_merchandise), str(act_merchandise))\n",
        "        merchandise_similarity /= len(standard_route['route'])\n",
        "\n",
        "        #total similarity calculating\n",
        "        total_similarity = (route_similarity + merchandise_similarity) / 2\n",
        "        similarities.append((standard_route_id, total_similarity))\n",
        "\n",
        "    # sort the max similarity\n",
        "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Find the most similar route\n",
        "    max_similarity = similarities[0]\n",
        "\n",
        "    # Store the most similar route for this actual route\n",
        "    most_similar_routes[act_route_id].append(max_similarity)\n",
        "\n",
        "    # If the actual route id is the same as the predicted route id, increment the correct prediction counter\n",
        "    if act_route_id == max_similarity[0]:\n",
        "        correct_predictions += 1\n",
        "\n",
        "# Print the most similar routes for all actual routes\n",
        "# for act_route_id, max_similarities in most_similar_routes.items():\n",
        "#    for i, max_similarity in enumerate(max_similarities):\n",
        "#        print(f\"Max similarity for actual route {act_route_id}-{i+1}: Standard Route {max_similarity[0]} with similarity {max_similarity[1]}\")\n",
        "\n",
        "# Calculate and print the prediction accuracy\n",
        "accuracy = correct_predictions / len(act_routes)\n",
        "print(f\"Prediction accuracy: {accuracy * 100}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdfcXzp1kVSA",
        "outputId": "72fe7015-a6c5-4efa-810f-1af1674fef6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 python-Levenshtein-0.21.1 rapidfuzz-3.1.1\n",
            "Prediction accuracy: 99.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'standard routes' file to Spark DataFrame\n",
        "import pandas as pd\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load data from JSON file\n",
        "with open('routes.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize an empty DataFrame to store the processed data\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate over each element\n",
        "for element in data:\n",
        "  id = element['id']\n",
        "\n",
        "# Iterate over routes\n",
        "  for route in element['route']:\n",
        "    from_city = route['from']\n",
        "    to_city = route['to']\n",
        "\n",
        "    # Iterate over merchandise\n",
        "    for merchandise, quantity in route['merchandise'].items():\n",
        "        # Append data to DataFrame\n",
        "        df = df.append({\n",
        "            'id': id,\n",
        "            'from': from_city,\n",
        "            'to': to_city,\n",
        "            'merchandise': merchandise,\n",
        "            'quantity': quantity\n",
        "        }, ignore_index=True)\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Convert DataFrame to Spark DataFrame\n",
        "st_routes_df = spark.createDataFrame(df)"
      ],
      "metadata": {
        "id": "uoS_LRqHXCNl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Create a new column that is the merchandise column value repeated quantity times\n",
        "str_df = st_routes_df.withColumn('merchandise_quantity', expr(\"repeat(merchandise, quantity)\"))\n",
        "str_df = str_df.drop('merchandise','quantity')\n",
        "\n",
        "str_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da0fAyHq0Q4J",
        "outputId": "767544ba-15ad-45db-d7f4-1eb3a6a267a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+-----------+--------------------+\n",
            "| id|       from|         to|merchandise_quantity|\n",
            "+---+-----------+-----------+--------------------+\n",
            "|  0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|  0|    Helmond|Schoonhoven|          honeyhoney|\n",
            "|  0|    Helmond|Schoonhoven|                pens|\n",
            "|  0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0|Schoonhoven|    Zaandam|               honey|\n",
            "+---+-----------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the duplicated routes\n",
        "stpaths = str_df.dropDuplicates([\"id\", \"from\", \"to\"])\n",
        "\n",
        "stpaths.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHfkTc_kHA5_",
        "outputId": "2fa975ce-47f3-4436-b8e0-d5eb85780727"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+------------+--------------------+\n",
            "| id|        from|          to|merchandise_quantity|\n",
            "+---+------------+------------+--------------------+\n",
            "|  0|     Helmond| Schoonhoven|waterwaterwaterwater|\n",
            "|  0| Schoonhoven|     Zaandam|waterwaterwaterwater|\n",
            "|  1|Klazienaveen|   The Hague|                pens|\n",
            "|  1|      Nuenen|Klazienaveen|penspenspenspensp...|\n",
            "|  2|    Enschede|   Harlingen|    milkmilkmilkmilk|\n",
            "+---+------------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "# Load data from JSON file\n",
        "with open('act_routes.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize an empty DataFrame to store the processed data\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Dictionary to store the counter for each unique ID\n",
        "id_counter = {}\n",
        "\n",
        "# Iterate over each element\n",
        "for element in data:\n",
        "    id = element['id']\n",
        "\n",
        "    # Increment the counter for each unique ID\n",
        "    if id in id_counter:\n",
        "        id_counter[id] += 1\n",
        "    else:\n",
        "        id_counter[id] = 1\n",
        "\n",
        "    # Counter for each ID\n",
        "    counter = id_counter[id]\n",
        "\n",
        "    # Iterate over routes\n",
        "    for route in element['route']:\n",
        "        from_city = route['from']\n",
        "        to_city = route['to']\n",
        "\n",
        "        # Iterate over merchandise\n",
        "        for merchandise, quantity in route['merchandise'].items():\n",
        "            # Append data to DataFrame with modified ID\n",
        "            df = df.append({\n",
        "                'id': f\"{id}-{counter}\",  # Assign modified ID with counter\n",
        "                'original_id': id,  # Store original ID\n",
        "                'from': from_city,\n",
        "                'to': to_city,\n",
        "                'merchandise': merchandise,\n",
        "                'quantity': quantity\n",
        "            }, ignore_index=True)\n",
        "\n",
        "# Convert DataFrame to Spark DataFrame\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "ac_routes_df = spark.createDataFrame(df)\n",
        "\n",
        "# Assign sequential counts to duplicate IDs\n",
        "ac_routes_df = ac_routes_df.withColumn('new_id', monotonically_increasing_id())\n"
      ],
      "metadata": {
        "id": "EpXKTrpdhTib"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine merchandies and quantity\n",
        "acr_df = ac_routes_df.withColumn('merchandise_quantity', expr(\"repeat(merchandise, quantity)\"))\n",
        "acr_df = acr_df.drop('merchandise', 'quantity', 'new_id')\n",
        "\n",
        "acr_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jcEdj7rKeBB",
        "outputId": "5f7f7b95-1b7c-4a50-a019-21934f1b8837"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+-----------+-----------+--------------------+\n",
            "| id|original_id|       from|         to|merchandise_quantity|\n",
            "+---+-----------+-----------+-----------+--------------------+\n",
            "|0-1|          0|Barendrecht|Schoonhoven|waterwaterwaterwater|\n",
            "|0-1|          0|Barendrecht|Schoonhoven|          honeyhoney|\n",
            "|0-1|          0|Barendrecht|Schoonhoven|                pens|\n",
            "|0-1|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|0-1|          0|Schoonhoven|    Zaandam|               honey|\n",
            "+---+-----------+-----------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the duplicated routes\n",
        "acpaths = acr_df.dropDuplicates([\"id\", \"original_id\", \"from\", \"to\"])\n",
        "\n",
        "acpaths.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ZxDm_V8GkW",
        "outputId": "5c2b12d9-f939-4171-ec7c-9dd0a570f6c3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+-----------+-----------+--------------------+\n",
            "|  id|original_id|       from|         to|merchandise_quantity|\n",
            "+----+-----------+-----------+-----------+--------------------+\n",
            "| 0-1|          0|Barendrecht|Schoonhoven|waterwaterwaterwater|\n",
            "| 0-1|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|0-10|          0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|0-10|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "| 0-2|          0|     Bergen|Schoonhoven|waterwaterwaterwater|\n",
            "+----+-----------+-----------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns\n",
        "pa_standard = stpaths.selectExpr(\"id as st_id\", \"from as st_from\", \"to as st_to\")\n",
        "pa_actual = acpaths.selectExpr(\"id as act_id\", \"original_id\", \"from as act_from\", \"to as act_to\")\n",
        "\n",
        "pa_actual.show()\n",
        "\n",
        "df_joined = pa_actual.join(pa_standard, (pa_actual.original_id == pa_standard.st_id), 'outer')\n",
        "\n",
        "df_joined.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVmfmim1Fipk",
        "outputId": "228d4cc0-8d1b-41f5-a326-309f14eac68f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+---------------+-------------------+\n",
            "|act_id|original_id|       act_from|             act_to|\n",
            "+------+-----------+---------------+-------------------+\n",
            "|   1-8|          1|   Klazienaveen|          The Hague|\n",
            "|  13-3|         13|         Raalte|   Koog aan de Zaan|\n",
            "|  23-7|         23|        Tilburg|           Schinnen|\n",
            "|  32-1|         32|    Heerlerbaan|             Leiden|\n",
            "| 40-10|         40|       Hillegom|        Heerlerbaan|\n",
            "|  77-6|         77|    Oosterwolde|         Oegstgeest|\n",
            "|  82-1|         82|        Leusden|           Ter Apel|\n",
            "|  89-9|         89|        Naarden|             Borger|\n",
            "|  94-8|         94|        Helmond|              Wezep|\n",
            "|135-10|        135|     Teijlingen|          Zandvoort|\n",
            "| 153-7|        153|          Zeist|Hendrik-Ido-Ambacht|\n",
            "| 160-6|        160|        Brummen|        Dedemsvaart|\n",
            "| 173-3|        173|     Schaesberg|                Oss|\n",
            "| 181-7|        181|      Landgraaf|       Monnickendam|\n",
            "| 208-5|        208|     Woudrichem|            Strijen|\n",
            "| 208-8|        208|     Woudrichem|            Strijen|\n",
            "| 212-3|        212|     Zaltbommel|         Doetinchem|\n",
            "| 213-4|        213|     Den Helder|          Barneveld|\n",
            "| 216-2|        216|Sint Willebrord|          Neerijnen|\n",
            "| 224-4|        224|   Badhoevedorp|            Leusden|\n",
            "+------+-----------+---------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+-----------+-----------+-----------+-----+-----------+-----------+\n",
            "|act_id|original_id|   act_from|     act_to|st_id|    st_from|      st_to|\n",
            "+------+-----------+-----------+-----------+-----+-----------+-----------+\n",
            "|   0-6|          0|    Helmond|Schoonhoven|    0|    Helmond|Schoonhoven|\n",
            "|   0-6|          0|    Helmond|Schoonhoven|    0|Schoonhoven|    Zaandam|\n",
            "|   0-1|          0|Schoonhoven|    Zaandam|    0|    Helmond|Schoonhoven|\n",
            "|   0-1|          0|Schoonhoven|    Zaandam|    0|Schoonhoven|    Zaandam|\n",
            "|   0-4|          0|    Helmond|Schoonhoven|    0|    Helmond|Schoonhoven|\n",
            "+------+-----------+-----------+-----------+-----+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from Levenshtein import distance\n",
        "\n",
        "def levenshtein_distance(s1, s2):\n",
        "    return distance(s1, s2)\n",
        "\n",
        "levenshtein_distance_udf = udf(levenshtein_distance, IntegerType())\n"
      ],
      "metadata": {
        "id": "B4TmnMW2BtIH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}