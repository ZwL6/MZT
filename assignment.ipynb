{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNA+MeqJmlExZzYP/XyQrxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZwL6/MZT/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vgGYzsiFZyE",
        "outputId": "2b321505-336f-44ab-93e8-22683a4118b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "openjdk-8-jdk-headless is already the newest version (8u372-ga~us1-0ubuntu1~20.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "nS9UM1hoFizF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cities file\n",
        "!wget https://raw.githubusercontent.com/ZwL6/MZT/main/cities.json\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcIZ1cyMJPs0",
        "outputId": "fc7476bc-573a-4e3d-be9b-c799886a3dc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-30 19:55:40--  https://raw.githubusercontent.com/ZwL6/MZT/main/cities.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15829 (15K) [text/plain]\n",
            "Saving to: ‘cities.json.3’\n",
            "\n",
            "\rcities.json.3         0%[                    ]       0  --.-KB/s               \rcities.json.3       100%[===================>]  15.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-30 19:55:40 (97.1 MB/s) - ‘cities.json.3’ saved [15829/15829]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making standerd route\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Set seed\n",
        "random.seed(1)\n",
        "with open('cities.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "cities = [d['city'] for d in data]\n",
        "\n",
        "merchandise = ['apple', 'tomatoes', 'butter', 'water', 'milk', 'pens', 'honey']\n",
        "\n",
        "routes = []\n",
        "\n",
        "for i in range(1000):\n",
        "    route = {}\n",
        "    route['id'] = i\n",
        "\n",
        "    # Generate a list of non-repeating random cities\n",
        "    city_sample = random.sample(cities, 3)\n",
        "\n",
        "    # Randomly generate the number of merchandise\n",
        "    num_merchandise = random.randint(1, 10)\n",
        "\n",
        "    # Randomly select merchandise types\n",
        "    merchandise_sample = random.sample(merchandise, random.randint(3, 5))\n",
        "\n",
        "    # Build the route dictionary format\n",
        "    route['route'] = []\n",
        "    for j in range(2):\n",
        "        route_info = {}\n",
        "        route_info['from'] = city_sample[j]\n",
        "        route_info['to'] = city_sample[j+1]\n",
        "\n",
        "        # Generate random merchandise quantities for each route\n",
        "        merchandise_dict = {}\n",
        "        for m in merchandise_sample:\n",
        "            merchandise_dict[m] = random.randint(1, num_merchandise)\n",
        "\n",
        "        route_info['merchandise'] = merchandise_dict\n",
        "\n",
        "        route['route'].append(route_info)\n",
        "\n",
        "    routes.append(route)\n",
        "\n",
        "# Write the route list to a JSON file without corrupt records\n",
        "valid_routes = [r for r in routes if 'route' in r and len(r['route']) == 2]\n",
        "with open('routes.json', 'w') as file:\n",
        "    json.dump(routes, file, indent=4)\n"
      ],
      "metadata": {
        "id": "qj8cYyhKSHBl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download routes\n",
        "# from google.colab import files\n",
        "# files.download('routes.json')\n"
      ],
      "metadata": {
        "id": "uNZs3ShmVCAl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making actual route\n",
        "\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "\n",
        "# Set seed\n",
        "random.seed(2)\n",
        "\n",
        "# Read the JSON file\n",
        "with open('cities.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract city names\n",
        "cities = [item['city'] for item in data]\n",
        "\n",
        "# Define merchandise types\n",
        "merchandise_types = ['apple', 'tomatoes', 'butter', 'water', 'milk', 'pens', 'honey']\n",
        "\n",
        "with open('routes.json', 'r') as file:\n",
        "    routes = json.load(file)\n",
        "\n",
        "act_routes = []\n",
        "\n",
        "for route in routes:\n",
        "    if len(route['route']) < 2:\n",
        "        continue  # Skip routes with less than two cities\n",
        "\n",
        "    for _ in range(10):\n",
        "        act_route = copy.deepcopy(route)  # Use deepcopy to avoid modifying the original route\n",
        "\n",
        "        # Randomly select a city to modify\n",
        "        modified_city_index = random.randint(0, len(act_route['route']) - 1)\n",
        "        modified_city = act_route['route'][modified_city_index]\n",
        "\n",
        "        # Randomly decide whether to modify city\n",
        "        if random.choice([True, False]):\n",
        "            # Modify the selected city\n",
        "            new_city = random.choice(cities)\n",
        "            modified_city['from'] = new_city\n",
        "\n",
        "            # If the modified city is the second city, modify it throughout the route\n",
        "            if modified_city_index == 1:\n",
        "                # Replace the modified city with a new city\n",
        "                act_route['route'][modified_city_index]['from'] = new_city\n",
        "                # Connect the cities before and after the replaced city\n",
        "                act_route['route'][modified_city_index - 1]['to'] = new_city\n",
        "                if modified_city_index + 1 < len(act_route['route']):\n",
        "                    act_route['route'][modified_city_index]['to'] = act_route['route'][modified_city_index + 1]['from']\n",
        "\n",
        "        # Randomly modify merchandise\n",
        "        for city_route in act_route['route']:\n",
        "          # Randomly decide whether to modify merchandise\n",
        "          if random.choice([True, False]):\n",
        "            # Select a random merchandise type\n",
        "            modified_merchandise = random.choice(list(city_route['merchandise'].keys()))\n",
        "            # Modify the quantity or replace the merchandise type\n",
        "            if random.choice([True, False]):\n",
        "              # Modify the quantity\n",
        "              city_route['merchandise'][modified_merchandise] = random.randint(1, 5)\n",
        "            else:\n",
        "              # Replace the merchandise type\n",
        "              new_merchandise = random.choice(merchandise_types)\n",
        "              if modified_merchandise in city_route['merchandise']:\n",
        "                city_route['merchandise'][new_merchandise] = city_route['merchandise'][modified_merchandise]\n",
        "                del city_route['merchandise'][modified_merchandise]\n",
        "\n",
        "\n",
        "        # Randomly modify merchandise\n",
        "        #for city_route in act_route['route']:\n",
        "            # Select random merchandise types\n",
        "            #selected_merchandise = random.sample(merchandise_types, random.randint(1, len(merchandise_types)))\n",
        "            # Assign random quantities to selected merchandise\n",
        "            #city_route['merchandise'] = {item: random.randint(1, 5) for item in selected_merchandise}\n",
        "\n",
        "        act_routes.append(act_route)\n",
        "\n",
        "# Write the act routes list to a new JSON file\n",
        "with open('act_routes.json', 'w') as file:\n",
        "    json.dump(act_routes, file, indent=4)"
      ],
      "metadata": {
        "id": "CGJurVstWvbv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the actual routes\n",
        "# from google.colab import files\n",
        "# files.download('act_routes.json')"
      ],
      "metadata": {
        "id": "WOqkwzTkX1L5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from Levenshtein import distance\n",
        "\n",
        "# Function for calculating route edit distance similarity\n",
        "def calculate_similarity(route1, route2):\n",
        "    lev_distance = distance(route1, route2)\n",
        "    max_length = max(len(route1), len(route2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# Function for calculating marchandise edit distance similarity\n",
        "def calculate_merchandise_similarity(merch1, merch2):\n",
        "    lev_distance = distance(merch1, merch2)\n",
        "    max_length = max(len(merch1), len(merch2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# open standard route file\n",
        "with open('routes.json', 'r') as file:\n",
        "    routes = json.load(file)\n",
        "\n",
        "# open actual route file\n",
        "with open('act_routes.json', 'r') as file:\n",
        "    act_routes = json.load(file)\n",
        "\n",
        "# Create a dictionary to store the most similar route for each actual route\n",
        "most_similar_routes = defaultdict(list)\n",
        "\n",
        "# Correct prediction counter\n",
        "correct_predictions = 0\n",
        "\n",
        "# Iterate through all actual routes\n",
        "for act_route in act_routes:\n",
        "    act_route_id = act_route['id']\n",
        "    act_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in act_route['route']])\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "    # route similarity calculating\n",
        "    for standard_route in routes:\n",
        "        standard_route_id = standard_route['id']\n",
        "        standard_route_str = ' '.join([f\"{route['from']} {route['to']}\" for route in standard_route['route']])\n",
        "\n",
        "        route_similarity = calculate_similarity(standard_route_str, act_route_str)\n",
        "\n",
        "        # merchandise similarity calculating\n",
        "        merchandise_similarity = 0\n",
        "        for i, route in enumerate(act_route['route']):\n",
        "            act_merchandise = route['merchandise']\n",
        "            standard_merchandise = standard_route['route'][0]['merchandise']\n",
        "            merchandise_similarity += calculate_merchandise_similarity(str(standard_merchandise), str(act_merchandise))\n",
        "        merchandise_similarity /= len(standard_route['route'])\n",
        "\n",
        "        #total similarity calculating\n",
        "        total_similarity = (route_similarity + merchandise_similarity) / 2\n",
        "        similarities.append((standard_route_id, total_similarity))\n",
        "\n",
        "    # sort the max similarity\n",
        "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Find the most similar route\n",
        "    max_similarity = similarities[0]\n",
        "\n",
        "    # Store the most similar route for this actual route\n",
        "    most_similar_routes[act_route_id].append(max_similarity)\n",
        "\n",
        "    # If the actual route id is the same as the predicted route id, increment the correct prediction counter\n",
        "    if act_route_id == max_similarity[0]:\n",
        "        correct_predictions += 1\n",
        "\n",
        "# Print the most similar routes for all actual routes\n",
        "# for act_route_id, max_similarities in most_similar_routes.items():\n",
        "#    for i, max_similarity in enumerate(max_similarities):\n",
        "#        print(f\"Max similarity for actual route {act_route_id}-{i+1}: Standard Route {max_similarity[0]} with similarity {max_similarity[1]}\")\n",
        "\n",
        "# Calculate and print the prediction accuracy\n",
        "accuracy = correct_predictions / len(act_routes)\n",
        "print(f\"Prediction accuracy: {accuracy * 100}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdfcXzp1kVSA",
        "outputId": "2cc678c0-291a-4562-cee8-eb728b244813"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
            "Prediction accuracy: 99.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'standard routes' file to Spark DataFrame\n",
        "import pandas as pd\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load data from JSON file\n",
        "with open('routes.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize an empty DataFrame to store the processed data\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate over each element\n",
        "for element in data:\n",
        "  id = element['id']\n",
        "\n",
        "# Iterate over routes\n",
        "  for route in element['route']:\n",
        "    from_city = route['from']\n",
        "    to_city = route['to']\n",
        "\n",
        "    # Iterate over merchandise\n",
        "    for merchandise, quantity in route['merchandise'].items():\n",
        "        # Append data to DataFrame\n",
        "        df = df.append({\n",
        "            'id': id,\n",
        "            'from': from_city,\n",
        "            'to': to_city,\n",
        "            'merchandise': merchandise,\n",
        "            'quantity': quantity\n",
        "        }, ignore_index=True)\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Convert DataFrame to Spark DataFrame\n",
        "st_routes_df = spark.createDataFrame(df)"
      ],
      "metadata": {
        "id": "uoS_LRqHXCNl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Create a new column that is the merchandise column value repeated quantity times\n",
        "str_df = st_routes_df.withColumn('merchandise_quantity', expr(\"repeat(merchandise, quantity)\"))\n",
        "str_df = str_df.drop('merchandise','quantity')\n",
        "\n",
        "str_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da0fAyHq0Q4J",
        "outputId": "4e54aac0-b1af-47ad-fb73-44809d84598f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+-----------+--------------------+\n",
            "| id|       from|         to|merchandise_quantity|\n",
            "+---+-----------+-----------+--------------------+\n",
            "|  0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|  0|    Helmond|Schoonhoven|          honeyhoney|\n",
            "|  0|    Helmond|Schoonhoven|                pens|\n",
            "|  0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0|Schoonhoven|    Zaandam|               honey|\n",
            "+---+-----------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STANDERD ROUTE\n",
        "from pyspark.sql.functions import concat_ws, collect_list\n",
        "\n",
        "# Group the dataframe by 'id', 'from', and 'to' and concatenate the 'merchandise_quantity' strings\n",
        "st_df = str_df.groupBy('id', 'from', 'to').agg(concat_ws('', collect_list('merchandise_quantity')).alias('combined_merchandise'))\n",
        "\n",
        "st_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkN20_DNp7ft",
        "outputId": "e726b162-5925-4d2f-d449-4c9d579bfb30"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+------------+--------------------+\n",
            "| id|        from|          to|combined_merchandise|\n",
            "+---+------------+------------+--------------------+\n",
            "|  0|     Helmond| Schoonhoven|waterwaterwaterwa...|\n",
            "|  0| Schoonhoven|     Zaandam|waterwaterwaterwa...|\n",
            "|  1|Klazienaveen|   The Hague|penstomatoestomat...|\n",
            "|  1|      Nuenen|Klazienaveen|penspenspenspensp...|\n",
            "|  2|    Enschede|   Harlingen|milkmilkmilkmilkt...|\n",
            "+---+------------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "# Load data from JSON file\n",
        "with open('act_routes.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize an empty DataFrame to store the processed data\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Dictionary to store the counter for each unique ID\n",
        "id_counter = {}\n",
        "\n",
        "# Iterate over each element\n",
        "for element in data:\n",
        "    id = element['id']\n",
        "\n",
        "    # Increment the counter for each unique ID\n",
        "    if id in id_counter:\n",
        "        id_counter[id] += 1\n",
        "    else:\n",
        "        id_counter[id] = 1\n",
        "\n",
        "    # Counter for each ID\n",
        "    counter = id_counter[id]\n",
        "\n",
        "    # Iterate over routes\n",
        "    for route in element['route']:\n",
        "        from_city = route['from']\n",
        "        to_city = route['to']\n",
        "\n",
        "        # Iterate over merchandise\n",
        "        for merchandise, quantity in route['merchandise'].items():\n",
        "            # Append data to DataFrame with modified ID\n",
        "            df = df.append({\n",
        "                'ac_id': f\"{id}-{counter}\",  # Assign modified ID with counter\n",
        "                'original_id': id,  # Store original ID\n",
        "                'from': from_city,\n",
        "                'to': to_city,\n",
        "                'merchandise': merchandise,\n",
        "                'quantity': quantity\n",
        "            }, ignore_index=True)\n",
        "\n",
        "# Convert DataFrame to Spark DataFrame\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "ac_routes_df = spark.createDataFrame(df)\n",
        "\n",
        "# Assign sequential counts to duplicate IDs\n",
        "ac_routes_df = ac_routes_df.withColumn('new_id', monotonically_increasing_id())\n"
      ],
      "metadata": {
        "id": "EpXKTrpdhTib"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine merchandies and quantity\n",
        "acr_df = ac_routes_df.withColumn('merchandise_quantity', expr(\"repeat(merchandise, quantity)\"))\n",
        "acr_df = acr_df.drop('merchandise', 'quantity', 'new_id')\n",
        "\n",
        "acr_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jcEdj7rKeBB",
        "outputId": "b16d5558-cc3b-4a42-c07b-4c831835fbf7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+-----------+-----------+--------------------+\n",
            "|ac_id|original_id|       from|         to|merchandise_quantity|\n",
            "+-----+-----------+-----------+-----------+--------------------+\n",
            "|  0-1|          0|Barendrecht|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-1|          0|Barendrecht|Schoonhoven|          honeyhoney|\n",
            "|  0-1|          0|Barendrecht|Schoonhoven|                pens|\n",
            "|  0-1|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0-1|          0|Schoonhoven|    Zaandam|               honey|\n",
            "+-----+-----------+-----------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ACTUAL ROUTE\n",
        "from pyspark.sql.functions import first\n",
        "\n",
        "# Group the dataframe by 'id', 'original_id', 'from', and 'to' and select the first 'merchandise_quantity' value\n",
        "ac_df = acr_df.groupby('ac_id', 'original_id', 'from', 'to').agg(first('merchandise_quantity').alias('combined_merchandise'))\n",
        "\n",
        "ac_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ich-PRw2rb-f",
        "outputId": "b48061cd-721f-484b-ba36-68459320eb04"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+-----------+-----------+--------------------+\n",
            "|ac_id|original_id|       from|         to|combined_merchandise|\n",
            "+-----+-----------+-----------+-----------+--------------------+\n",
            "|  0-1|          0|Barendrecht|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-1|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "| 0-10|          0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "| 0-10|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0-2|          0|     Bergen|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-2|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0-3|          0|    Helmond|Schoonhoven|          honeyhoney|\n",
            "|  0-3|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0-4|          0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-4|          0|Schoonhoven|    Zaandam|     waterwaterwater|\n",
            "|  0-5|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0-5|          0|  Staphorst|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-6|          0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-6|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0-7|          0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-7|          0|Schoonhoven|    Zaandam|               water|\n",
            "|  0-8|          0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-8|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "|  0-9|          0|    Helmond|Schoonhoven|waterwaterwaterwater|\n",
            "|  0-9|          0|Schoonhoven|    Zaandam|waterwaterwaterwater|\n",
            "+-----+-----------+-----------+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf, concat_ws, collect_list, first\n",
        "from pyspark.sql.functions import row_number\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import FloatType\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Define a UDF to calculate similarity\n",
        "def calculate_similarity(str1, str2):\n",
        "    lev_distance = distance(str1, str2)\n",
        "    max_length = max(len(str1), len(str2))\n",
        "    similarity = 1 - lev_distance / max_length\n",
        "    return similarity\n",
        "\n",
        "# Register the UDF\n",
        "similarity_udf = udf(calculate_similarity, FloatType())\n",
        "\n",
        "# Rename the columns 'from' and 'to' in ac_df and st_df\n",
        "ac_df = ac_df.withColumnRenamed('from', 'ac_from').withColumnRenamed('to', 'ac_to')\n",
        "st_df = st_df.withColumnRenamed('from', 'st_from').withColumnRenamed('to', 'st_to')\n",
        "a_df = ac_df.select(col('ac_id'), col('original_id'), col('ac_from'), col('ac_to'), col('combined_merchandise'))\n",
        "s_df = st_df.select(col('id'), col('st_from'), col('st_to'), col('combined_merchandise'))\n",
        "\n",
        "# Combine the actual routes with the same act_id\n",
        "a_df = a_df.groupBy('ac_id').agg(first('original_id').alias('original_id'), concat_ws(' ', collect_list('ac_from'), collect_list('ac_to'), collect_list('combined_merchandise')).alias('combined_route'))\n",
        "\n",
        "# Combine the standard routes with the same id\n",
        "s_df = s_df.groupBy('id').agg(concat_ws(' ', collect_list('st_from'), collect_list('st_to'), collect_list('combined_merchandise')).alias('st_combined_route'))\n",
        "\n",
        "# Calculate similarity using cross join and UDF\n",
        "ac_st_df = a_df.crossJoin(s_df)\n",
        "ac_st_df = ac_st_df.withColumn('similarity', similarity_udf(ac_st_df['combined_route'], ac_st_df['st_combined_route']))\n",
        "\n",
        "# Find the most similar route for each actual route\n",
        "window = Window.partitionBy(ac_st_df['ac_id']).orderBy(ac_st_df['similarity'].desc())\n",
        "ac_st_df = ac_st_df.withColumn('rank', row_number().over(window))\n",
        "most_similar_routes = ac_st_df.filter(ac_st_df['rank'] == 1).select('original_id', 'id', 'similarity')\n",
        "\n",
        "# Count the correct predictions\n",
        "correct_predictions = most_similar_routes.filter(most_similar_routes['original_id'] == most_similar_routes['id']).count()\n",
        "\n",
        "# Select the highest similarity result for each actual route\n",
        "#highest_similarity = ac_st_df.filter(ac_st_df['rank'] == 1).select('ac_id', 'original_id', 'id', 'similarity')\n",
        "\n",
        "# Print the result of the highest similarity for each actual route\n",
        "#highest_similarity.show(truncate=False)\n",
        "\n",
        "# Calculate and print the prediction accuracy\n",
        "accuracy = correct_predictions / ac_df.count()\n",
        "print(f\"Prediction accuracy: {accuracy * 100}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZXwooIE_JWa",
        "outputId": "2c433305-43ec-43a3-8d36-f1c479e5c71d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+---+----------+\n",
            "|ac_id |original_id|id |similarity|\n",
            "+------+-----------+---+----------+\n",
            "|0-8   |0          |0  |0.69827586|\n",
            "|0-9   |0          |0  |0.69827586|\n",
            "|1-1   |1          |220|0.4021739 |\n",
            "|1-2   |1          |52 |0.4017094 |\n",
            "|1-3   |1          |741|0.43421054|\n",
            "|1-7   |1          |1  |0.5510204 |\n",
            "|1-8   |1          |52 |0.3846154 |\n",
            "|10-6  |10         |10 |0.37190083|\n",
            "|10-7  |10         |10 |0.5785124 |\n",
            "|10-8  |10         |10 |0.6859504 |\n",
            "|100-1 |100        |894|0.39506173|\n",
            "|100-10|100        |302|0.44186047|\n",
            "|100-3 |100        |975|0.375     |\n",
            "|100-4 |100        |703|0.35714287|\n",
            "|100-5 |100        |36 |0.33846155|\n",
            "|100-6 |100        |138|0.34375   |\n",
            "|100-7 |100        |421|0.3611111 |\n",
            "|100-8 |100        |339|0.31355932|\n",
            "|100-9 |100        |180|0.36363637|\n",
            "|101-10|101        |987|0.41111112|\n",
            "+------+-----------+---+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Prediction accuracy: 17.43%\n"
          ]
        }
      ]
    }
  ]
}